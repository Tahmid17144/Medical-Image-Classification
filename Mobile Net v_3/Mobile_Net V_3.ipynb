{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f1a48e-7974-42ba-a5ff-5b6f623e364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV3Large\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17551d8-4d9e-4999-9e61-e2827fef4702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4571 images belonging to 4 classes.\n",
      "Found 262 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\TAHMID HOSSAIN\\Desktop\\data\\train',  # Replace with the path to your dataset\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\TAHMID HOSSAIN\\Desktop\\data\\val',  # Replace with the path to your dataset\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea2169d-27cd-46c4-8d56-8338d41c0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetv3_model():\n",
    "    base_model = MobileNetV3Large(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze the base model for transfer learning\n",
    "\n",
    "    # Add custom classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)  # Optional extra dense layer\n",
    "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the complete model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model, base_model\n",
    "\n",
    "# Unpack both model and base_model\n",
    "model, base_model = create_mobilenetv3_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e577465-7c1e-4363-b77a-bc18ed84ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access base_model by name or index, depending on the setup\n",
    "base_model = model.layers[0]\n",
    "base_model.trainable = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "310c8e24-0af6-4935-9e54-770b66783ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - accuracy: 0.2642 - loss: 1.4457 - val_accuracy: 0.3906 - val_loss: 1.3765\n",
      "Epoch 2/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4219 - loss: 1.3205 - val_accuracy: 0.3333 - val_loss: 1.3759\n",
      "Epoch 3/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.3924 - loss: 1.3063 - val_accuracy: 0.4102 - val_loss: 1.3303\n",
      "Epoch 4/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4219 - loss: 1.2238 - val_accuracy: 0.6667 - val_loss: 1.3773\n",
      "Epoch 5/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.4821 - loss: 1.2439 - val_accuracy: 0.5156 - val_loss: 1.3140\n",
      "Epoch 6/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 1.2131 - val_accuracy: 0.3333 - val_loss: 1.6621\n",
      "Epoch 7/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.5321 - loss: 1.2049 - val_accuracy: 0.5430 - val_loss: 1.3117\n",
      "Epoch 8/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5156 - loss: 1.2344 - val_accuracy: 0.1667 - val_loss: 1.6838\n",
      "Epoch 9/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.5496 - loss: 1.1774 - val_accuracy: 0.5352 - val_loss: 1.3226\n",
      "Epoch 10/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7031 - loss: 1.0716 - val_accuracy: 0.3333 - val_loss: 1.1309\n",
      "Epoch 11/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - accuracy: 0.5398 - loss: 1.1719 - val_accuracy: 0.5078 - val_loss: 1.3202\n",
      "Epoch 12/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 1.1475 - val_accuracy: 0.5000 - val_loss: 1.2388\n",
      "Epoch 13/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.5367 - loss: 1.1613 - val_accuracy: 0.5156 - val_loss: 1.3154\n",
      "Epoch 14/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6719 - loss: 1.0776 - val_accuracy: 0.3333 - val_loss: 1.3936\n",
      "Epoch 15/15\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.5653 - loss: 1.1467 - val_accuracy: 0.5078 - val_loss: 1.3012\n"
     ]
    }
   ],
   "source": [
    "# Recompile with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune for a few additional epochs\n",
    "history_fine_tune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=15\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "415c10d9-1a08-423e-81e8-fa3017c9687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4928 - loss: 1.3284\n",
      "Validation Loss: 1.316095232963562\n",
      "Validation Accuracy: 0.5038167834281921\n",
      "Epoch 1/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.5624 - loss: 1.1296 - val_accuracy: 0.4922 - val_loss: 1.3118\n",
      "Epoch 2/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5469 - loss: 1.1682 - val_accuracy: 0.1667 - val_loss: 1.5679\n",
      "Epoch 3/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.6036 - loss: 1.1261 - val_accuracy: 0.5117 - val_loss: 1.3130\n",
      "Epoch 4/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 1.1408 - val_accuracy: 0.6667 - val_loss: 1.2403\n",
      "Epoch 5/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.5906 - loss: 1.1053 - val_accuracy: 0.5078 - val_loss: 1.3056\n",
      "Epoch 6/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 1.2120 - val_accuracy: 0.5000 - val_loss: 1.3594\n",
      "Epoch 7/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.6074 - loss: 1.0992 - val_accuracy: 0.4961 - val_loss: 1.3007\n",
      "Epoch 8/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6667 - loss: 1.1294 - val_accuracy: 0.6667 - val_loss: 1.1741\n",
      "Epoch 9/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.5996 - loss: 1.0873 - val_accuracy: 0.4844 - val_loss: 1.3005\n",
      "Epoch 10/10\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5625 - loss: 1.1234 - val_accuracy: 0.8333 - val_loss: 0.7691\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Loss: {loss}')\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "base_model.trainable = True\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train again with fine-tuning\n",
    "history_fine_tune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=10  # Fine-tune for a few additional epochs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f80f7-c6fd-4fd1-9173-dedb872a4bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
